#include "utils/structs.glsl"
#include "utils/sampler2d.glsl"
#include "utils/sampler3d.glsl"

#include "utils/classification.glsl"
#include "utils/compositing.glsl"
#include "utils/depth.glsl"
#include "utils/gradients.glsl"
#include "utils/shading.glsl"
#include "utils/raycastgeometry.glsl"

#include "random.glsl"
#include "transmittancemethods.glsl"
#include "renderingmethods.glsl"

// volume
uniform sampler3D volume;
uniform VolumeParameters volumeParameters;

// entry
uniform sampler2D entryColor;
uniform sampler2D entryDepth;
uniform ImageParameters entryParameters;

// exit
uniform sampler2D exitColor;
uniform sampler2D exitDepth;
uniform ImageParameters exitParameters;

// output
uniform layout(binding=0, rgba8) image2D outportColor;
writeonly uniform image2D outportDepth;
writeonly uniform image2D outportPicking;
uniform ImageParameters outportParameters;

// Uniform properties
uniform CameraParameters camera;
uniform VolumeIndicatorParameters positionindicator;
uniform RaycastingParameters raycaster;
uniform LightParameters light; //lighting
uniform sampler2D transferFunction; // cant get transferFunction up to a compute shader?

uniform int channel;

uniform float time_ms;
uniform int iteration;

#define ERT_THRESHOLD 0.99  // threshold for early ray termination

#define PI 3.1415

layout (local_size_x = 16, local_size_y = 16) in;

float calcStep(in float rayLength, in vec3 direction, in float samplingRate, in vec3 dimensions) {
    float incr = min(rayLength, rayLength / (samplingRate * length(direction * dimensions)));
    float samples = ceil(rayLength / incr);
    return rayLength / samples;
}

vec3 calcCameraDir(in vec3 entryPoint, in vec3 exitPoint, in mat4 textureToWorld) {
    return normalize(
        (textureToWorld * vec4(entryPoint, 1.0) - textureToWorld * vec4(exitPoint, 1.0)).xyz);
}

vec4 simpleRender(ImageParameters outParam, vec3 entryPoint, vec3 exitPoint, float entryDepth, float exitDepth,
    inout float depth, RaycastingParameters rayCastParam, VolumeParameters volParam, vec4 bgColor) {

    vec4 result = vec4(0.0);   // The accumulated color along the ray;
    vec4 picking = vec4(0.0);  // The picking color of the ray
    float rayDepth = -1.0;     // The ray depth value [0, ray length], -1 means "no" depth.
                               // Uses the same space as rayPosition. Usually used to track
                               // the depth of the "first" hit in DVR.
    depth = 1.0;         // The image depth, from far to near [0, 1].
                               // Will be overridden by rayDepth if != -1 and then
                               // written to outportDepth

    vec4 outColor = vec4(0);
    float outDepth = 0;

    vec3 ray = exitPoint - entryPoint;
    vec3 rayDir = normalize(ray);  
    float rayLength = length(ray);  

    uint globalDimX = gl_WorkGroupSize.x*gl_NumWorkGroups.x;
    uint globalDimY = gl_WorkGroupSize.y*gl_NumWorkGroups.y;
    uint gid = gl_GlobalInvocationID.x + gl_GlobalInvocationID.y*globalDimX;

    float rayStep = calcStep(rayLength, rayDir, rayCastParam.samplingRate, volParam.dimensions);
    vec3 cameraDir = calcCameraDir(entryPoint, exitPoint, volParam.textureToWorld);

    float rayPosition = 0.5 * rayStep;
    vec3 samplePosition = entryPoint + rayPosition * rayDir;
    float T = 1.0f;
    float tau = 1f;
    float meanpath = WoodcockTracking(samplePosition, rayDir, rayLength, gid + time_ms,
            volume, volumeParameters, transferFunction, 1f, tau);
    rayPosition = meanpath; 
    

    int safety = 0;

    if (rayPosition <= rayLength) {
        samplePosition = entryPoint + rayPosition * rayDir;
        

        // Sample volume.
        vec4 voxel = getNormalizedVoxel(volume, volumeParameters, samplePosition);
        vec4 color = applyTF(transferFunction, voxel);

        PlaneParameters[6] planes = constructBBPlanes(volumeParameters);

        vec3 sampleWorldPosition = (volumeParameters.textureToWorld*vec4(samplePosition,1f)).xyz;

        // Function is broken for testing at the moment.
        result = RMVolumeRender_SingleBounceLight(T, meanpath, volume, volumeParameters, transferFunction, result, 
            samplePosition, cameraDir, light, planes, gid + time_ms + 1);
        T = SimpleTracking(T, meanpath, tau);

        #pragma IVW_SHADER_SEGMENT_PLACEHOLDER_LOOP
    }
    result = result + T*bgColor;

    depth = mix(calculateDepthValue(camera, rayDepth / rayLength, entryDepth, exitDepth),
                depth, rayDepth == -1.0);

    return result;
}
/*
vec4 simplePathTracer(ImageParameters outParam, vec3 entryPoint, vec3 exitPoint, float entryDepth, float exitDepth,
    inout float depth, RaycastingParameters rayCastParam, VolumeParameters volParam, vec4 bgColor) {
    
    vec4 result = vec4(0.0);   // The accumulated color along the ray;
    vec4 picking = vec4(0.0);  // The picking color of the ray
    float rayDepth = -1.0;     // The ray depth value [0, ray length], -1 means "no" depth.
                               // Uses the same space as rayPosition. Usually used to track
                               // the depth of the "first" hit in DVR.
    depth = 1.0;         // The image depth, from far to near [0, 1].
                               // Will be overridden by rayDepth if != -1 and then
                               // written to outportDepth

    vec4 outColor = vec4(0);
    float outDepth = 0;

    vec3 ray = exitPoint - entryPoint;
    vec3 rayDir = normalize(ray);
    float rayLength = length(ray);

    uint globalDimX = gl_WorkGroupSize.x*gl_NumWorkGroups.x;
    uint globalDimY = gl_WorkGroupSize.y*gl_NumWorkGroups.y;
    uint gid = gl_GlobalInvocationID.x + gl_GlobalInvocationID.y*globalDimX;

    float rayStep = calcStep(rayLength, rayDir, rayCastParam.samplingRate, volParam.dimensions);
    float travel = rayStep * 0.5;

    vec3 pos = entryPoint + travel * rayDir;  
    vec3 pointLight = vec3(2, 2, 2);
    float pointLightStrength = 7f;

    float theta = 0.01*(random_1dto1d(gid + floatBitsToUint(time_ms))*2*PI);
    
    //float theta = 0*(PI/180f);

    float phi = 0.005*(random_1dto1d(gid + 1  + floatBitsToUint(time_ms))*2*PI - PI);
    
    //float phi = 0*(PI/180f);

    rayDir = rotateFrom(rayDir, theta, phi);
    int safety_count = 0;

    float T = 1f;
    for(travel += rayStep; travel < rayLength;) {

        pos = entryPoint + rayDir*travel;
        
        // TODO: Can we remove the artifacts when looking through the z direction?
        // They seem to be caused by a higher init phi rayDir randomisation
        rayDir = rotateFrom(rayDir, theta, phi);
        theta = 0.1*(random_1dto1d(floatBitsToUint(theta))*2*PI);
        phi = 0.05*(random_1dto1d(floatBitsToUint(phi))*2*PI - PI);

        
        // Sample volume.
        vec4 voxel = getNormalizedVoxel(volume, volumeParameters, pos);
        vec4 color = applyTF(transferFunction, voxel)/255.0;
        
        // using gid aside to time_ms as hashseed is MUCH slower, 
        // but we see a clear dependence between pixel points. Is it caching?

        float meanpath = WoodcockTracking(pos, rayDir, rayLength, gid,
            volume, volumeParameters, transferFunction, 50);
        travel += meanpath;

        vec3 worldPos = (volumeParameters.textureToWorld*vec4(pos,1f)).xyz;
        
        //result = RMVolumeRender_simpleWithLight(T, meanpath, color.a*700.0, color*700.0, result, 
        //    worldPos, pointLight, pointLightStrength);
        
        T = SimpleTracking(T, meanpath, color.a*700.0);

        safety_count++;
        if(safety_count > 100) break; // no infinite loops
        
        if (T < 0.01) break;  // early ray termination
    }

    result = result + T*bgColor;

    depth = mix(calculateDepthValue(camera, rayDepth / rayLength, entryDepth, exitDepth),
                depth, rayDepth == -1.0);
    
    
    return result;
}
*/
void main(){

    vec4 result = vec4(0.0);   // The accumulated color along the ray;
    vec4 picking = vec4(0.0);  // The picking color of the ray
    float rayDepth = -1.0;     // The ray depth value [0, ray length], -1 means "no" depth.
                               // Uses the same space as rayPosition. Usually used to track
                               // the depth of the "first" hit in DVR.
    float depth = 1.0;         // The image depth, from far to near [0, 1].
                               // Will be overridden by rayDepth if != -1 and then
                               // written to outportDepth

    ivec2 storePos = ivec2(gl_GlobalInvocationID.xy);
    vec2 texCoord = vec2(gl_GlobalInvocationID.xy) / outportParameters.dimensions;

    

    vec3 entryPoint = texture(entryColor, texCoord).xyz;
    vec3 exitPoint = texture(exitColor, texCoord).xyz;

    float entryPointDepth = texture(entryDepth, texCoord).x;
    float exitPointDepth = texture(exitDepth, texCoord).x;

    // alpha channel barely does anything...
    vec4 bgColor = vec4(0.0f, 0.0f, 0.0f, 1.0f)*1f;

    if (entryPoint == exitPoint) {
        imageStore(outportColor, storePos, bgColor); 
        imageStore(outportDepth, storePos, vec4(depth, depth, depth, 255)); 
        imageStore(outportPicking, storePos, picking);
        return;
    }


    result += simpleRender(outportParameters, entryPoint, exitPoint, entryPointDepth, exitPointDepth,
            depth, raycaster, volumeParameters, bgColor);
    // If you wanna normalize, DONT do it based off of results. It needs to be a global factor

    vec4 resPrev = imageLoad(outportColor, storePos);

    // mix between outputColor and now and new one
    // TODO: need uniform iteration
    float w = 1.0f - 1.0f/float(iteration + 1);
    //w = 1.0f;
    vec4 finalresult = mix(result, resPrev, w);

    imageStore(outportColor, storePos, finalresult);     
    imageStore(outportDepth, storePos, vec4(depth, depth, depth, 255)); 
    imageStore(outportPicking, storePos, picking);
}
